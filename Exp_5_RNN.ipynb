{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "0ioU09OmfvqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QttrKBhLxlyD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/poems-100.csv')"
      ],
      "metadata": {
        "id": "McAjHGDrF0C7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Rq5OA1npF0F7",
        "outputId": "809a6137-f453-4cf9-d7a7-6cde31839ea6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  O my Luve's like a red, red rose\\nThat’s newly...\n",
              "1  The rose is red,\\nThe violet's blue,\\nSugar is...\n",
              "2  How do I love thee? Let me count the ways.\\nI ...\n",
              "3  Had I the heavens' embroidered cloths,\\nEnwrou...\n",
              "4  I.\\n    Enough! we're tired, my heart and I.\\n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c48c199a-adc2-45de-9b40-aa5dec7491f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O my Luve's like a red, red rose\\nThat’s newly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The rose is red,\\nThe violet's blue,\\nSugar is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do I love thee? Let me count the ways.\\nI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Had I the heavens' embroidered cloths,\\nEnwrou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I.\\n    Enough! we're tired, my heart and I.\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c48c199a-adc2-45de-9b40-aa5dec7491f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c48c199a-adc2-45de-9b40-aa5dec7491f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c48c199a-adc2-45de-9b40-aa5dec7491f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Three little birds in a row\\nSat musing.\\nA man passed near that place.\\nThen did the little birds nudge each other.\\n\\nThey said, \\\"He thinks he can sing.\\\"\\nThey threw back their heads to laugh.\\nWith quaint countenances\\nThey regarded him.\\nThey were very curious,\\nThose three little birds in a row.\",\n          \"  I think I could turn and live with animals, they are so placid and\\n      self-contain'd,\\n  I stand and look at them long and long.\\n\\n  They do not sweat and whine about their condition,\\n  They do not lie awake in the dark and weep for their sins,\\n  They do not make me sick discussing their duty to God,\\n  Not one is dissatisfied, not one is demented with the mania of\\n      owning things,\\n  Not one kneels to another, nor to his kind that lived thousands of\\n      years ago,\\n  Not one is respectable or unhappy over the whole earth.\\n\\n  So they show their relations to me and I accept them,\\n  They bring me tokens of myself, they evince them plainly in their\\n      possession.\\n\\n  I wonder where they get those tokens,\\n  Did I pass that way huge times ago and negligently drop them?\\n\\n  Myself moving forward then and now and forever,\\n  Gathering and showing more always and with velocity,\\n  Infinite and omnigenous, and the like of these among them,\\n  Not too exclusive toward the reachers of my remembrancers,\\n  Picking out here one that I love, and now go with him on brotherly terms.\\n\\n  A gigantic beauty of a stallion, fresh and responsive to my caresses,\\n  Head high in the forehead, wide between the ears,\\n  Limbs glossy and supple, tail dusting the ground,\\n  Eyes full of sparkling wickedness, ears finely cut, flexibly moving.\\n\\n  His nostrils dilate as my heels embrace him,\\n  His well-built limbs tremble with pleasure as we race around and return.\\n\\n  I but use you a minute, then I resign you, stallion,\\n  Why do I need your paces when I myself out-gallop them?\\n  Even as I stand or sit passing faster than you.\",\n          \"  And as to you Death, and you bitter hug of mortality, it is idle to\\n      try to alarm me.\\n\\n  To his work without flinching the accoucheur comes,\\n  I see the elder-hand pressing receiving supporting,\\n  I recline by the sills of the exquisite flexible doors,\\n  And mark the outlet, and mark the relief and escape.\\n\\n  And as to you Corpse I think you are good manure, but that does not\\n      offend me,\\n  I smell the white roses sweet-scented and growing,\\n  I reach to the leafy lips, I reach to the polish'd breasts of melons.\\n\\n  And as to you Life I reckon you are the leavings of many deaths,\\n  (No doubt I have died myself ten thousand times before.)\\n\\n  I hear you whispering there O stars of heaven,\\n  O suns\\u2014O grass of graves\\u2014O perpetual transfers and promotions,\\n  If you do not say any thing how can I say any thing?\\n\\n  Of the turbid pool that lies in the autumn forest,\\n  Of the moon that descends the steeps of the soughing twilight,\\n  Toss, sparkles of day and dusk\\u2014toss on the black stems that decay\\n      in the muck,\\n  Toss to the moaning gibberish of the dry limbs.\\n\\n  I ascend from the moon, I ascend from the night,\\n  I perceive that the ghastly glimmer is noonday sunbeams reflected,\\n  And debouch to the steady and central from the offspring great or small.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7N0T_X_F0JX",
        "outputId": "22008e78-00a8-4335-fe28-b24e3c4e6d6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "1rchmoSEf1YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = []\n",
        "\n",
        "for raw_text in df[\"text\"].fillna(\"\").map(str):\n",
        "    normalized = raw_text.lower()\n",
        "    stripped = re.compile(r'[^a-z\\s]').sub(\"\", normalized)\n",
        "    tokens += stripped.split()\n",
        "\n",
        "unique_terms = list(set(tokens))\n",
        "unique_terms.sort()\n",
        "\n",
        "size_of_vocab = len(unique_terms)\n",
        "\n",
        "term_to_id = dict(zip(unique_terms, range(size_of_vocab)))\n",
        "id_to_term = {idx: term for term, idx in term_to_id.items()}"
      ],
      "metadata": {
        "id": "8OmqQMsIGD8K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary size:\", size_of_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P67J-4KzIuFv",
        "outputId": "11a7c2b2-009f-4d0d-d8d1-796bdb04a6df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 5439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample words:\", unique_terms[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o1PfpLhI3qr",
        "outputId": "2ac64fd1-b28d-42e8-adda-0742ccf39573"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample words: ['a', 'abase', 'abased', 'abbeystones', 'abeyance', 'abide', 'abode', 'abodes', 'about', 'above']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_words = [term_to_id[w] for w in tokens]"
      ],
      "metadata": {
        "id": "oUnN06VjI7LB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First 20 encoded words:\")\n",
        "print(encoded_words[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx-LxTlVJZja",
        "outputId": "be14065b-401b-4e26-f583-5cf1fe5f0fae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 20 encoded words:\n",
            "[3167, 3054, 2775, 2664, 0, 3748, 3748, 3897, 4726, 3109, 4407, 2351, 2473, 3167, 3054, 2775, 2664, 4727, 2896, 4726]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 5\n",
        "X=[]\n",
        "y=[]"
      ],
      "metadata": {
        "id": "OG4Zi69eJ4iu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "while i+SEQ_LEN<len(encoded_words):\n",
        "  X.append(encoded_words[i:i+SEQ_LEN])\n",
        "  y.append(encoded_words[i+SEQ_LEN])\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "fOORzkvuKiP6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X)\n",
        "y = torch.tensor(y)"
      ],
      "metadata": {
        "id": "GrkJgcc8OTbD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSNNrcvjOUZ5",
        "outputId": "05c54672-9a39-4894-acbb-a896cfc24ad4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([24671, 5])\n",
            "Target shape: torch.Size([24671])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN From Scratch"
      ],
      "metadata": {
        "id": "AIEZA9Onf6gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN_Numpy:\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        scale = 0.01\n",
        "        h_dim = hidden_size\n",
        "        v_dim = vocab_size\n",
        "\n",
        "        self.Wxh = scale * np.random.randn(h_dim, v_dim)\n",
        "        self.Whh = scale * np.random.randn(h_dim, h_dim)\n",
        "        self.Why = scale * np.random.randn(v_dim, h_dim)\n",
        "\n",
        "        self.bh = np.zeros((h_dim, 1))\n",
        "        self.by = np.zeros((v_dim, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        hidden_dim = self.bh.shape[0]\n",
        "        state = np.zeros((hidden_dim, 1))\n",
        "        result = []\n",
        "        for step in range(len(inputs)):\n",
        "            vec = np.expand_dims(inputs[step], axis=1)\n",
        "            pre_activation = (\n",
        "                np.dot(self.Wxh, vec) +\n",
        "                np.dot(self.Whh, state) +\n",
        "                self.bh\n",
        "            )\n",
        "            state = np.tanh(pre_activation)\n",
        "            out = np.dot(self.Why, state) + self.by\n",
        "            result.append(out)\n",
        "        return result"
      ],
      "metadata": {
        "id": "_StGj-SBOe0_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_np = SimpleRNN_Numpy(size_of_vocab, hidden_size=32)\n",
        "print(\"NumPy RNN initialized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8rFpl-vOrMs",
        "outputId": "79805452-be9d-493d-96d5-34eec5936101"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy RNN initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One Hot Encoding Approach"
      ],
      "metadata": {
        "id": "sSojH7_QgPl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_onehot = torch.zeros(X.size(0), SEQ_LEN, size_of_vocab)\n",
        "\n",
        "for i in range(X.size(0)):\n",
        "    for t in range(SEQ_LEN):\n",
        "        X_onehot[i, t, X[i, t]] = 1\n",
        "\n",
        "print(\"One-hot input shape:\", X_onehot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW9iiSCwO0xY",
        "outputId": "b816004d-037a-4cf8-e8d0-013b39a29e03"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot input shape: torch.Size([24671, 5, 5439])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHotRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(OneHotRNN, self).__init__()\n",
        "        input_dim = vocab_size\n",
        "        hidden_dim = hidden_size\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, hidden_state = self.rnn(x)\n",
        "        last_step = rnn_output[:, rnn_output.size(1) - 1]\n",
        "        logits = self.fc(last_step)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "0LLnkBH_PLZ8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_model = OneHotRNN(size_of_vocab, 128)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    params=onehot_model.parameters(),\n",
        "    lr=3e-3\n",
        ")\n",
        "print(onehot_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbBwfZWyPhTG",
        "outputId": "2d5e75de-cdae-45d6-aa55-931072eb32ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OneHotRNN(\n",
            "  (rnn): RNN(5439, 128, batch_first=True)\n",
            "  (fc): Linear(in_features=128, out_features=5439, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch_idx in range(1, 11):\n",
        "    predictions = onehot_model(X_onehot)\n",
        "    loss = criterion(predictions, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "onehot_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "ZMzbxKdJcY1T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final One-Hot Loss:\", loss.item())\n",
        "print(\"One-Hot Training Time:\", onehot_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xiZl1T1cY7H",
        "outputId": "a3d72793-7fd4-4053-e1bc-ecb7d913a101"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final One-Hot Loss: 6.762184143066406\n",
            "One-Hot Training Time: 111.4195032119751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_onehot(start_word, length=15, temperature=1.0):\n",
        "    words = [start_word]\n",
        "    onehot_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            inp = torch.zeros((1, SEQ_LEN, size_of_vocab))\n",
        "            recent = words[-SEQ_LEN:]\n",
        "\n",
        "            for i, token in enumerate(recent):\n",
        "                if token in term_to_id:\n",
        "                    inp[0, i, term_to_id[token]] = 1\n",
        "\n",
        "            logits = onehot_model(inp)\n",
        "            probs = torch.softmax(logits / temperature, dim=1)\n",
        "            chosen_index = torch.multinomial(probs, 1).item()\n",
        "            next_word = id_to_term[chosen_index]\n",
        "\n",
        "            words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(\"One-hot Sample:\", generate_onehot(\"love\", temperature=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GyxU4EsdUvz",
        "outputId": "f9f128b8-44e5-4d30-85e6-579a96718fff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot Sample: love what you a words up the be the time o how like little the or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Embedding Approach"
      ],
      "metadata": {
        "id": "6mJKpnrOgYjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(EmbeddingRNN, self).__init__()\n",
        "\n",
        "        v_dim = vocab_size\n",
        "        e_dim = embed_size\n",
        "        h_dim = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=v_dim,\n",
        "            embedding_dim=e_dim\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=e_dim,\n",
        "            hidden_size=h_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(h_dim, v_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        rnn_out, hidden = self.rnn(embedded)\n",
        "\n",
        "        final_step = rnn_out[:, rnn_out.size(1) - 1]\n",
        "        logits = self.fc(final_step)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "embed_model = EmbeddingRNN(size_of_vocab, 100, 128)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    params=embed_model.parameters(),\n",
        "    lr=3e-3\n",
        ")"
      ],
      "metadata": {
        "id": "nUmS9eQKen3M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxYRBeFodU1t",
        "outputId": "09e3a662-1200-48ec-f2a9-690e39ed3240"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmbeddingRNN(\n",
            "  (embedding): Embedding(5439, 100)\n",
            "  (rnn): RNN(100, 128, batch_first=True)\n",
            "  (fc): Linear(in_features=128, out_features=5439, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "max_epochs = 10\n",
        "epoch_idx = 0\n",
        "while epoch_idx < max_epochs:\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    preds = embed_model(X)\n",
        "    loss_embed = criterion(preds, y)\n",
        "    loss_embed.backward()\n",
        "    optimizer.step()\n",
        "    epoch_idx += 1\n",
        "\n",
        "embed_time = time.time() - start_time\n",
        "\n",
        "final_loss_value = loss_embed.item()\n",
        "print(\"Final Embedding Loss:\", final_loss_value)\n",
        "print(\"Embedding Training Time:\", embed_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry5_wxLNdU4E",
        "outputId": "73d645a8-16eb-4b5a-948e-c516e2d47a91"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Embedding Loss: 6.801928520202637\n",
            "Embedding Training Time: 38.527023792266846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final One-Hot Loss:\", loss.item())\n",
        "print(\"Final Embedding Loss:\", loss_embed.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLzUIklhfDwi",
        "outputId": "e09b1aa5-8479-4e4c-fb96-aa2889e269ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final One-Hot Loss: 6.762184143066406\n",
            "Final Embedding Loss: 6.801928520202637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n========= COMPARISON SUMMARY =========\")\n",
        "print(f\"One-Hot Encoding  -> Loss: {loss.item():.4f}, Time: {onehot_time:.2f}s\")\n",
        "print(f\"Word Embeddings   -> Loss: {loss_embed.item():.4f}, Time: {embed_time:.2f}s\")\n",
        "\n",
        "if loss_embed.item() < loss.item():\n",
        "    print(\"Embedding model performs better based on loss.\")\n",
        "else:\n",
        "    print(\"One-Hot model performs better based on loss.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdd-yDZ6fJVG",
        "outputId": "15145894-7b7b-47b1-b951-8727761fd204"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========= COMPARISON SUMMARY =========\n",
            "One-Hot Encoding  -> Loss: 6.7622, Time: 111.42s\n",
            "Word Embeddings   -> Loss: 6.8019, Time: 38.53s\n",
            "One-Hot model performs better based on loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embedding(start_word, length=15, temperature=1.0):\n",
        "    words = [start_word]\n",
        "    embed_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            recent_words = words[-SEQ_LEN:]\n",
        "            indices = [term_to_id[w] for w in recent_words if w in term_to_id]\n",
        "\n",
        "            if len(indices) < SEQ_LEN:\n",
        "                indices = [0] * (SEQ_LEN - len(indices)) + indices\n",
        "\n",
        "            seq = torch.tensor(indices).view(1, -1)\n",
        "            logits = embed_model(seq)\n",
        "\n",
        "            probs = torch.softmax(logits / temperature, dim=1)\n",
        "            best_idx = torch.multinomial(probs, 1).item()\n",
        "            next_word = id_to_term[best_idx]\n",
        "\n",
        "            words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(\"Embedding Sample:\", generate_embedding(\"love\", temperature=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVSDT2o5foW7",
        "outputId": "98698b42-0741-427a-9042-306df1389af4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Sample: love trees which and enough will with from oaths at shelf but there might has your\n"
          ]
        }
      ]
    }
  ]
}