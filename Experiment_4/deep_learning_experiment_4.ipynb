{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rVFHRCUbF7Ih"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import csv\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQLZ8WGAGKP7",
        "outputId": "d93e5bc6-925b-400c-fcaf-30091949de59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a319V0lCGhtc",
        "outputId": "f209620d-9ace-43f3-a21b-3749515e16e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " audio_files.zip        HateMM_annotation.csv   sampleSubmission.csv\n",
            "'Colab Notebooks'       hate_videos.zip         test1.zip\n",
            "'Getting started.pdf'   non_hate_videos.zip     train.zip\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ExfWA3vaIHpN"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/test1.zip -d test-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6MerU3nHIWov"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/train.zip -d train-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TK7uuu395ybR"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYdxWWBdx8ag",
        "outputId": "28e30836-9c23-4420-be0c-25570db05010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-6yRL3zYyKBG"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "LR = 0.001\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ukYfiIVCyFp_"
      },
      "outputs": [],
      "source": [
        "# Loading CIFAR10 dataset\n",
        "def load_cifar10():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                             (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    train_set = datasets.CIFAR10(\n",
        "        root=\"./data\", train=True, download=True, transform=transform\n",
        "    )\n",
        "    test_set = datasets.CIFAR10(\n",
        "        root=\"./data\", train=False, download=True, transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6XQ86gG0yU_P"
      },
      "outputs": [],
      "source": [
        "#Importing labels from csv file for comparing test data of cat dog classification\n",
        "def load_labels_from_csv(csv_path):\n",
        "    label_dict = {}\n",
        "    with open(csv_path, \"r\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            label_dict[row[\"id\"]] = int(row[\"label\"])\n",
        "    return label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6lYsPu5nyZpb"
      },
      "outputs": [],
      "source": [
        "class CatsDogsDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None, labels=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.labels is None:\n",
        "            label = 0 if img_name.startswith(\"cat\") else 1\n",
        "        else:\n",
        "            img_id = os.path.splitext(img_name)[0]\n",
        "            label = self.labels[img_id]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Pfd4X7e0ypID"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "def load_cats_dogs():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                             (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    train_dataset = CatsDogsDataset(\n",
        "        \"/content/train-dataset/train\",\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    labels = load_labels_from_csv(\n",
        "        \"/content/drive/MyDrive/sampleSubmission.csv\"\n",
        "    )\n",
        "\n",
        "    test_dataset = CatsDogsDataset(\n",
        "        \"/content/test-dataset/test1\",\n",
        "        transform=transform,\n",
        "        labels=labels\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LuPBIZf1yQ6V"
      },
      "outputs": [],
      "source": [
        "# CNN Model\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes, activation, dataset_name):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        if dataset_name == \"cifar10\":\n",
        "            self.model = nn.Sequential(\n",
        "                nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                activation,\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                activation,\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                activation,\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(128 * 4 * 4, 256),\n",
        "                activation,\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(256, num_classes)\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            # Cats vs Dogs → 224x224 images\n",
        "            self.model = nn.Sequential(\n",
        "                nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                activation,\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                activation,\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                activation,\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(128 * 28 * 28, 256),\n",
        "                activation,\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(256, num_classes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DqjfxX4Ly_xx"
      },
      "outputs": [],
      "source": [
        "# Initializing weights\n",
        "def init_weights(model, init_type):\n",
        "    for layer in model.modules():\n",
        "        if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "            if init_type == \"xavier\":\n",
        "                nn.init.xavier_uniform_(layer.weight)\n",
        "            elif init_type == \"kaiming\":\n",
        "                nn.init.kaiming_uniform_(layer.weight, nonlinearity=\"relu\")\n",
        "            else:\n",
        "                nn.init.normal_(layer.weight, mean=0.0, std=0.02)\n",
        "            if layer.bias is not None:\n",
        "                nn.init.constant_(layer.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ODwL0LkQzFrS"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    correct, total = 0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gQOcj8vGzL-d"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oOt00GzvzPj-"
      },
      "outputs": [],
      "source": [
        "def run(train_loader, test_loader, dataset_name, num_classes, save_path,EPOCHS):\n",
        "    activations = {\n",
        "        \"ReLU\": nn.ReLU(),\n",
        "        \"Tanh\": nn.Tanh(),\n",
        "        \"LeakyReLU\": nn.LeakyReLU(0.1)\n",
        "    }\n",
        "    weight_inits = [\"xavier\", \"kaiming\", \"random\"]\n",
        "    optimizers = {\n",
        "        \"SGD\": optim.SGD,\n",
        "        \"Adam\": optim.Adam,\n",
        "        \"RMSprop\": optim.RMSprop\n",
        "    }\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_test_acc = 0.0\n",
        "    for act_name, act_fn in activations.items():\n",
        "        for init_name in weight_inits:\n",
        "            for opt_name, opt_class in optimizers.items():\n",
        "                print(f\"\\nRunning: {act_name} | {init_name} | {opt_name}\")\n",
        "                model = CustomCNN(\n",
        "                    num_classes=num_classes,\n",
        "                    activation=act_fn,\n",
        "                    dataset_name=dataset_name\n",
        "                ).to(device)\n",
        "                init_weights(model, init_name)\n",
        "                optimizer = opt_class(model.parameters(), lr=LR)\n",
        "\n",
        "                for epoch in range(EPOCHS):\n",
        "                    train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "                    test_acc = evaluate(model, test_loader)\n",
        "                    print(\n",
        "                        f\"Epoch [{epoch+1}/{EPOCHS}] \"\n",
        "                        f\"Train Acc: {train_acc:.2f}% | \"\n",
        "                        f\"Test Acc: {test_acc:.2f}%\"\n",
        "                    )\n",
        "                if test_acc > best_test_acc:\n",
        "                    best_test_acc = test_acc\n",
        "                    torch.save(model.state_dict(), save_path)\n",
        "                    print(\"Best model saved\")\n",
        "    print(f\"\\nBest Test Accuracy: {best_test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-TkNKyZ4zVzX"
      },
      "outputs": [],
      "source": [
        "def train_resnet18(train_loader, test_loader, num_classes):\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    print(\"\\nTraining ResNet-18\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "        test_acc = evaluate(model, test_loader)\n",
        "        print(f\"Epoch {epoch+1}: Train={train_acc:.2f}% Test={test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading CIFAR dataset and running model"
      ],
      "metadata": {
        "id": "otEr0lJ9eMtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"                                         CIFAR-10\")\n",
        "cifar_train, cifar_test = load_cifar10()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ivi8U_Ebs3f",
        "outputId": "0799e246-208b-48b6-e55b-4dfc9d9c6317"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         CIFAR-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "533ec9cb",
        "outputId": "71829d0f-55f8-422c-951b-a1fb6d7af600"
      },
      "source": [
        "images, labels = next(iter(cifar_train))\n",
        "print(f\"Shape of one image batch from cifar_train: {images.shape}\")\n",
        "print(f\"Shape of one label batch from cifar_train: {labels.shape}\")\n",
        "\n",
        "images, labels = next(iter(cifar_test))\n",
        "print(f\"Shape of one image batch from cifar_test: {images.shape}\")\n",
        "print(f\"Shape of one label batch from cifar_test: {labels.shape}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of one image batch from cifar_train: torch.Size([64, 3, 32, 32])\n",
            "Shape of one label batch from cifar_train: torch.Size([64])\n",
            "Shape of one image batch from cifar_test: torch.Size([64, 3, 32, 32])\n",
            "Shape of one label batch from cifar_test: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjdriJNqzyN4",
        "outputId": "e4a97f70-ee94-47a8-a6f0-6215704bdee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running: ReLU | xavier | SGD\n",
            "Epoch [1/5] Train Acc: 27.75% | Test Acc: 40.80%\n",
            "Epoch [2/5] Train Acc: 36.98% | Test Acc: 45.60%\n",
            "Epoch [3/5] Train Acc: 41.31% | Test Acc: 48.30%\n",
            "Epoch [4/5] Train Acc: 43.88% | Test Acc: 50.91%\n",
            "Epoch [5/5] Train Acc: 46.36% | Test Acc: 52.94%\n",
            "Best model saved\n",
            "\n",
            "Running: ReLU | xavier | Adam\n",
            "Epoch [1/5] Train Acc: 41.42% | Test Acc: 56.95%\n",
            "Epoch [2/5] Train Acc: 55.16% | Test Acc: 64.29%\n",
            "Epoch [3/5] Train Acc: 61.25% | Test Acc: 68.68%\n",
            "Epoch [4/5] Train Acc: 64.93% | Test Acc: 71.79%\n",
            "Epoch [5/5] Train Acc: 67.69% | Test Acc: 73.58%\n",
            "Best model saved\n",
            "\n",
            "Running: ReLU | xavier | RMSprop\n",
            "Epoch [1/5] Train Acc: 36.23% | Test Acc: 48.71%\n",
            "Epoch [2/5] Train Acc: 52.24% | Test Acc: 61.42%\n",
            "Epoch [3/5] Train Acc: 58.62% | Test Acc: 63.15%\n",
            "Epoch [4/5] Train Acc: 62.41% | Test Acc: 63.18%\n",
            "Epoch [5/5] Train Acc: 64.71% | Test Acc: 69.06%\n",
            "\n",
            "Running: ReLU | kaiming | SGD\n",
            "Epoch [1/5] Train Acc: 24.64% | Test Acc: 37.63%\n",
            "Epoch [2/5] Train Acc: 33.40% | Test Acc: 42.68%\n",
            "Epoch [3/5] Train Acc: 37.22% | Test Acc: 44.72%\n",
            "Epoch [4/5] Train Acc: 40.18% | Test Acc: 47.12%\n",
            "Epoch [5/5] Train Acc: 41.57% | Test Acc: 48.42%\n",
            "\n",
            "Running: ReLU | kaiming | Adam\n",
            "Epoch [1/5] Train Acc: 39.15% | Test Acc: 54.96%\n",
            "Epoch [2/5] Train Acc: 52.06% | Test Acc: 64.03%\n",
            "Epoch [3/5] Train Acc: 57.55% | Test Acc: 65.47%\n",
            "Epoch [4/5] Train Acc: 61.63% | Test Acc: 69.59%\n",
            "Epoch [5/5] Train Acc: 64.32% | Test Acc: 71.49%\n",
            "\n",
            "Running: ReLU | kaiming | RMSprop\n",
            "Epoch [1/5] Train Acc: 37.99% | Test Acc: 47.50%\n",
            "Epoch [2/5] Train Acc: 52.81% | Test Acc: 58.03%\n",
            "Epoch [3/5] Train Acc: 58.87% | Test Acc: 64.41%\n",
            "Epoch [4/5] Train Acc: 62.35% | Test Acc: 64.47%\n",
            "Epoch [5/5] Train Acc: 65.89% | Test Acc: 62.60%\n",
            "\n",
            "Running: ReLU | random | SGD\n",
            "Epoch [1/5] Train Acc: 26.90% | Test Acc: 39.58%\n",
            "Epoch [2/5] Train Acc: 38.51% | Test Acc: 45.52%\n",
            "Epoch [3/5] Train Acc: 43.91% | Test Acc: 49.38%\n",
            "Epoch [4/5] Train Acc: 47.66% | Test Acc: 52.74%\n",
            "Epoch [5/5] Train Acc: 50.64% | Test Acc: 53.54%\n",
            "\n",
            "Running: ReLU | random | Adam\n",
            "Epoch [1/5] Train Acc: 49.56% | Test Acc: 62.79%\n",
            "Epoch [2/5] Train Acc: 62.70% | Test Acc: 66.77%\n",
            "Epoch [3/5] Train Acc: 67.75% | Test Acc: 72.41%\n",
            "Epoch [4/5] Train Acc: 70.80% | Test Acc: 73.96%\n",
            "Epoch [5/5] Train Acc: 73.70% | Test Acc: 74.86%\n",
            "Best model saved\n",
            "\n",
            "Running: ReLU | random | RMSprop\n",
            "Epoch [1/5] Train Acc: 41.98% | Test Acc: 49.91%\n",
            "Epoch [2/5] Train Acc: 56.60% | Test Acc: 60.65%\n",
            "Epoch [3/5] Train Acc: 62.60% | Test Acc: 56.49%\n",
            "Epoch [4/5] Train Acc: 66.53% | Test Acc: 68.84%\n",
            "Epoch [5/5] Train Acc: 68.73% | Test Acc: 70.33%\n",
            "\n",
            "Running: Tanh | xavier | SGD\n",
            "Epoch [1/5] Train Acc: 26.85% | Test Acc: 40.77%\n",
            "Epoch [2/5] Train Acc: 36.93% | Test Acc: 45.04%\n",
            "Epoch [3/5] Train Acc: 41.10% | Test Acc: 47.53%\n",
            "Epoch [4/5] Train Acc: 43.95% | Test Acc: 49.06%\n",
            "Epoch [5/5] Train Acc: 46.07% | Test Acc: 50.80%\n",
            "\n",
            "Running: Tanh | xavier | Adam\n",
            "Epoch [1/5] Train Acc: 43.69% | Test Acc: 56.55%\n",
            "Epoch [2/5] Train Acc: 57.99% | Test Acc: 60.82%\n",
            "Epoch [3/5] Train Acc: 63.92% | Test Acc: 66.10%\n",
            "Epoch [4/5] Train Acc: 67.81% | Test Acc: 68.32%\n",
            "Epoch [5/5] Train Acc: 70.38% | Test Acc: 72.08%\n",
            "\n",
            "Running: Tanh | xavier | RMSprop\n",
            "Epoch [1/5] Train Acc: 40.93% | Test Acc: 49.28%\n",
            "Epoch [2/5] Train Acc: 56.04% | Test Acc: 44.29%\n",
            "Epoch [3/5] Train Acc: 61.93% | Test Acc: 63.63%\n",
            "Epoch [4/5] Train Acc: 66.03% | Test Acc: 61.65%\n",
            "Epoch [5/5] Train Acc: 68.45% | Test Acc: 66.12%\n",
            "\n",
            "Running: Tanh | kaiming | SGD\n",
            "Epoch [1/5] Train Acc: 22.98% | Test Acc: 36.00%\n",
            "Epoch [2/5] Train Acc: 32.43% | Test Acc: 41.38%\n",
            "Epoch [3/5] Train Acc: 37.07% | Test Acc: 44.07%\n",
            "Epoch [4/5] Train Acc: 39.62% | Test Acc: 46.29%\n",
            "Epoch [5/5] Train Acc: 41.88% | Test Acc: 47.63%\n",
            "\n",
            "Running: Tanh | kaiming | Adam\n",
            "Epoch [1/5] Train Acc: 44.06% | Test Acc: 57.13%\n",
            "Epoch [2/5] Train Acc: 58.58% | Test Acc: 64.52%\n",
            "Epoch [3/5] Train Acc: 64.54% | Test Acc: 67.23%\n",
            "Epoch [4/5] Train Acc: 68.19% | Test Acc: 68.67%\n",
            "Epoch [5/5] Train Acc: 71.07% | Test Acc: 70.92%\n",
            "\n",
            "Running: Tanh | kaiming | RMSprop\n",
            "Epoch [1/5] Train Acc: 40.28% | Test Acc: 49.87%\n",
            "Epoch [2/5] Train Acc: 55.16% | Test Acc: 57.95%\n",
            "Epoch [3/5] Train Acc: 61.59% | Test Acc: 60.42%\n",
            "Epoch [4/5] Train Acc: 65.38% | Test Acc: 62.86%\n",
            "Epoch [5/5] Train Acc: 68.23% | Test Acc: 64.88%\n",
            "\n",
            "Running: Tanh | random | SGD\n",
            "Epoch [1/5] Train Acc: 25.62% | Test Acc: 33.90%\n",
            "Epoch [2/5] Train Acc: 34.94% | Test Acc: 39.40%\n",
            "Epoch [3/5] Train Acc: 39.99% | Test Acc: 42.51%\n",
            "Epoch [4/5] Train Acc: 42.93% | Test Acc: 44.47%\n",
            "Epoch [5/5] Train Acc: 45.43% | Test Acc: 40.39%\n",
            "\n",
            "Running: Tanh | random | Adam\n",
            "Epoch [1/5] Train Acc: 47.53% | Test Acc: 57.47%\n",
            "Epoch [2/5] Train Acc: 59.31% | Test Acc: 63.60%\n",
            "Epoch [3/5] Train Acc: 64.32% | Test Acc: 67.27%\n",
            "Epoch [4/5] Train Acc: 67.81% | Test Acc: 70.06%\n",
            "Epoch [5/5] Train Acc: 70.36% | Test Acc: 70.96%\n",
            "\n",
            "Running: Tanh | random | RMSprop\n",
            "Epoch [1/5] Train Acc: 43.36% | Test Acc: 48.83%\n",
            "Epoch [2/5] Train Acc: 55.32% | Test Acc: 53.54%\n",
            "Epoch [3/5] Train Acc: 60.49% | Test Acc: 58.58%\n",
            "Epoch [4/5] Train Acc: 64.72% | Test Acc: 55.77%\n",
            "Epoch [5/5] Train Acc: 67.49% | Test Acc: 65.92%\n",
            "\n",
            "Running: LeakyReLU | xavier | SGD\n",
            "Epoch [1/5] Train Acc: 28.51% | Test Acc: 42.77%\n",
            "Epoch [2/5] Train Acc: 38.29% | Test Acc: 47.39%\n",
            "Epoch [3/5] Train Acc: 42.43% | Test Acc: 50.18%\n",
            "Epoch [4/5] Train Acc: 45.50% | Test Acc: 51.90%\n",
            "Epoch [5/5] Train Acc: 47.78% | Test Acc: 54.04%\n",
            "\n",
            "Running: LeakyReLU | xavier | Adam\n",
            "Epoch [1/5] Train Acc: 47.46% | Test Acc: 63.85%\n",
            "Epoch [2/5] Train Acc: 64.04% | Test Acc: 68.79%\n",
            "Epoch [3/5] Train Acc: 70.16% | Test Acc: 73.09%\n",
            "Epoch [4/5] Train Acc: 74.34% | Test Acc: 72.20%\n",
            "Epoch [5/5] Train Acc: 77.10% | Test Acc: 74.97%\n",
            "Best model saved\n",
            "\n",
            "Running: LeakyReLU | xavier | RMSprop\n",
            "Epoch [1/5] Train Acc: 43.70% | Test Acc: 52.01%\n",
            "Epoch [2/5] Train Acc: 61.44% | Test Acc: 59.61%\n",
            "Epoch [3/5] Train Acc: 68.68% | Test Acc: 69.01%\n",
            "Epoch [4/5] Train Acc: 73.03% | Test Acc: 70.35%\n",
            "Epoch [5/5] Train Acc: 76.07% | Test Acc: 65.28%\n",
            "\n",
            "Running: LeakyReLU | kaiming | SGD\n",
            "Epoch [1/5] Train Acc: 25.04% | Test Acc: 38.99%\n",
            "Epoch [2/5] Train Acc: 34.81% | Test Acc: 43.53%\n",
            "Epoch [3/5] Train Acc: 38.83% | Test Acc: 46.17%\n",
            "Epoch [4/5] Train Acc: 41.27% | Test Acc: 48.19%\n",
            "Epoch [5/5] Train Acc: 43.51% | Test Acc: 49.84%\n",
            "\n",
            "Running: LeakyReLU | kaiming | Adam\n",
            "Epoch [1/5] Train Acc: 47.23% | Test Acc: 62.28%\n",
            "Epoch [2/5] Train Acc: 63.81% | Test Acc: 70.20%\n",
            "Epoch [3/5] Train Acc: 70.00% | Test Acc: 72.53%\n",
            "Epoch [4/5] Train Acc: 73.78% | Test Acc: 74.52%\n",
            "Epoch [5/5] Train Acc: 77.24% | Test Acc: 74.89%\n",
            "\n",
            "Running: LeakyReLU | kaiming | RMSprop\n",
            "Epoch [1/5] Train Acc: 44.61% | Test Acc: 51.82%\n",
            "Epoch [2/5] Train Acc: 61.67% | Test Acc: 61.93%\n",
            "Epoch [3/5] Train Acc: 68.84% | Test Acc: 70.85%\n",
            "Epoch [4/5] Train Acc: 72.97% | Test Acc: 67.27%\n",
            "Epoch [5/5] Train Acc: 76.24% | Test Acc: 67.27%\n",
            "\n",
            "Running: LeakyReLU | random | SGD\n",
            "Epoch [1/5] Train Acc: 27.23% | Test Acc: 41.33%\n",
            "Epoch [2/5] Train Acc: 39.34% | Test Acc: 46.93%\n",
            "Epoch [3/5] Train Acc: 44.21% | Test Acc: 51.34%\n",
            "Epoch [4/5] Train Acc: 48.32% | Test Acc: 49.84%\n",
            "Epoch [5/5] Train Acc: 51.62% | Test Acc: 53.02%\n",
            "\n",
            "Running: LeakyReLU | random | Adam\n",
            "Epoch [1/5] Train Acc: 51.49% | Test Acc: 64.18%\n",
            "Epoch [2/5] Train Acc: 65.90% | Test Acc: 70.96%\n",
            "Epoch [3/5] Train Acc: 70.81% | Test Acc: 73.69%\n",
            "Epoch [4/5] Train Acc: 74.60% | Test Acc: 76.33%\n",
            "Epoch [5/5] Train Acc: 77.54% | Test Acc: 76.65%\n",
            "Best model saved\n",
            "\n",
            "Running: LeakyReLU | random | RMSprop\n",
            "Epoch [1/5] Train Acc: 45.68% | Test Acc: 51.53%\n",
            "Epoch [2/5] Train Acc: 61.51% | Test Acc: 62.79%\n",
            "Epoch [3/5] Train Acc: 68.14% | Test Acc: 63.94%\n",
            "Epoch [4/5] Train Acc: 72.51% | Test Acc: 66.82%\n",
            "Epoch [5/5] Train Acc: 75.51% | Test Acc: 67.36%\n",
            "\n",
            "Best Test Accuracy: 76.65%\n",
            "\n",
            "Training ResNet-18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train=39.77% Test=43.51%\n",
            "Epoch 2: Train=44.24% Test=45.27%\n",
            "Epoch 3: Train=44.84% Test=45.97%\n",
            "Epoch 4: Train=45.04% Test=45.42%\n",
            "Epoch 5: Train=45.10% Test=44.84%\n"
          ]
        }
      ],
      "source": [
        "run(\n",
        "    train_loader=cifar_train,\n",
        "    test_loader=cifar_test,\n",
        "    dataset_name=\"cifar10\",\n",
        "    num_classes=10,\n",
        "    save_path=\"best_cnn_cifar10.pth\",\n",
        "    EPOCHS=5\n",
        ")\n",
        "train_resnet18(cifar_train, cifar_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading cat dog dataset and running model"
      ],
      "metadata": {
        "id": "x6lspgVDeae5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd_train, cd_test = load_cats_dogs()"
      ],
      "metadata": {
        "id": "T_6SwgYDcESE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cbf2ddd",
        "outputId": "b6327a6f-4066-4f25-dfbf-8420b664f6af"
      },
      "source": [
        "images, labels = next(iter(cd_train))\n",
        "print(f\"Shape of one image batch from cd_train: {images.shape}\")\n",
        "print(f\"Shape of one label batch from cd_train: {labels.shape}\")\n",
        "\n",
        "images, labels = next(iter(cd_test))\n",
        "print(f\"Shape of one image batch from cd_test: {images.shape}\")\n",
        "print(f\"Shape of one label batch from cd_test: {labels.shape}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of one image batch from cd_train: torch.Size([32, 3, 224, 224])\n",
            "Shape of one label batch from cd_train: torch.Size([32])\n",
            "Shape of one image batch from cd_test: torch.Size([32, 3, 224, 224])\n",
            "Shape of one label batch from cd_test: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML4btQ_Iz6U5",
        "outputId": "b0bdb684-9a92-4471-949f-2e3280727fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           Cats vs Dogs\n",
            "\n",
            "Running: ReLU | xavier | SGD\n",
            "Epoch [1/3] Train Acc: 64.43% | Test Acc: 59.40%\n",
            "Epoch [2/3] Train Acc: 71.38% | Test Acc: 36.40%\n",
            "Epoch [3/3] Train Acc: 74.67% | Test Acc: 59.18%\n",
            "Best model saved\n",
            "\n",
            "Running: ReLU | xavier | Adam\n",
            "Epoch [1/3] Train Acc: 60.70% | Test Acc: 70.54%\n",
            "Epoch [2/3] Train Acc: 62.27% | Test Acc: 70.07%\n",
            "Epoch [3/3] Train Acc: 62.40% | Test Acc: 72.16%\n",
            "Best model saved\n",
            "\n",
            "Running: ReLU | xavier | RMSprop\n",
            "Epoch [1/3] Train Acc: 56.39% | Test Acc: 45.31%\n",
            "Epoch [2/3] Train Acc: 56.27% | Test Acc: 86.96%\n",
            "Epoch [3/3] Train Acc: 58.29% | Test Acc: 68.40%\n",
            "\n",
            "Running: ReLU | kaiming | SGD\n",
            "Epoch [1/3] Train Acc: 63.98% | Test Acc: 73.65%\n",
            "Epoch [2/3] Train Acc: 69.67% | Test Acc: 48.15%\n",
            "Epoch [3/3] Train Acc: 73.03% | Test Acc: 50.66%\n",
            "\n",
            "Running: ReLU | kaiming | Adam\n",
            "Epoch [1/3] Train Acc: 58.95% | Test Acc: 66.30%\n",
            "Epoch [2/3] Train Acc: 62.66% | Test Acc: 52.36%\n",
            "Epoch [3/3] Train Acc: 64.47% | Test Acc: 63.02%\n",
            "\n",
            "Running: ReLU | kaiming | RMSprop\n",
            "Epoch [1/3] Train Acc: 57.46% | Test Acc: 48.26%\n",
            "Epoch [2/3] Train Acc: 58.10% | Test Acc: 8.26%\n",
            "Epoch [3/3] Train Acc: 61.30% | Test Acc: 34.02%\n",
            "\n",
            "Running: ReLU | random | SGD\n",
            "Epoch [1/3] Train Acc: 61.48% | Test Acc: 49.15%\n",
            "Epoch [2/3] Train Acc: 66.64% | Test Acc: 73.42%\n",
            "Epoch [3/3] Train Acc: 69.32% | Test Acc: 40.50%\n",
            "\n",
            "Running: ReLU | random | Adam\n",
            "Epoch [1/3] Train Acc: 59.90% | Test Acc: 40.50%\n",
            "Epoch [2/3] Train Acc: 63.34% | Test Acc: 62.02%\n",
            "Epoch [3/3] Train Acc: 63.69% | Test Acc: 71.10%\n",
            "\n",
            "Running: ReLU | random | RMSprop\n",
            "Epoch [1/3] Train Acc: 59.38% | Test Acc: 88.42%\n",
            "Epoch [2/3] Train Acc: 56.43% | Test Acc: 82.48%\n",
            "Epoch [3/3] Train Acc: 57.82% | Test Acc: 83.54%\n",
            "Best model saved\n",
            "\n",
            "Running: Tanh | xavier | SGD\n",
            "Epoch [1/3] Train Acc: 62.70% | Test Acc: 56.79%\n",
            "Epoch [2/3] Train Acc: 68.66% | Test Acc: 42.48%\n",
            "Epoch [3/3] Train Acc: 71.94% | Test Acc: 32.74%\n",
            "\n",
            "Running: Tanh | xavier | Adam\n",
            "Epoch [1/3] Train Acc: 55.33% | Test Acc: 51.69%\n",
            "Epoch [2/3] Train Acc: 57.59% | Test Acc: 48.92%\n",
            "Epoch [3/3] Train Acc: 56.83% | Test Acc: 45.78%\n",
            "\n",
            "Running: Tanh | xavier | RMSprop\n",
            "Epoch [1/3] Train Acc: 56.53% | Test Acc: 49.74%\n",
            "Epoch [2/3] Train Acc: 56.62% | Test Acc: 48.17%\n",
            "Epoch [3/3] Train Acc: 55.91% | Test Acc: 40.82%\n",
            "\n",
            "Running: Tanh | kaiming | SGD\n",
            "Epoch [1/3] Train Acc: 62.51% | Test Acc: 51.06%\n",
            "Epoch [2/3] Train Acc: 68.36% | Test Acc: 40.33%\n",
            "Epoch [3/3] Train Acc: 72.24% | Test Acc: 64.06%\n",
            "\n",
            "Running: Tanh | kaiming | Adam\n",
            "Epoch [1/3] Train Acc: 57.30% | Test Acc: 60.21%\n",
            "Epoch [2/3] Train Acc: 60.98% | Test Acc: 42.88%\n",
            "Epoch [3/3] Train Acc: 61.78% | Test Acc: 42.37%\n",
            "\n",
            "Running: Tanh | kaiming | RMSprop\n",
            "Epoch [1/3] Train Acc: 57.20% | Test Acc: 40.98%\n",
            "Epoch [2/3] Train Acc: 59.57% | Test Acc: 49.86%\n",
            "Epoch [3/3] Train Acc: 60.50% | Test Acc: 51.70%\n",
            "\n",
            "Running: Tanh | random | SGD\n",
            "Epoch [1/3] Train Acc: 58.90% | Test Acc: 52.03%\n",
            "Epoch [2/3] Train Acc: 62.90% | Test Acc: 49.60%\n",
            "Epoch [3/3] Train Acc: 64.62% | Test Acc: 53.58%\n",
            "\n",
            "Running: Tanh | random | Adam\n",
            "Epoch [1/3] Train Acc: 54.91% | Test Acc: 51.62%\n",
            "Epoch [2/3] Train Acc: 56.14% | Test Acc: 39.29%\n",
            "Epoch [3/3] Train Acc: 56.77% | Test Acc: 56.34%\n",
            "\n",
            "Running: Tanh | random | RMSprop\n",
            "Epoch [1/3] Train Acc: 52.96% | Test Acc: 65.46%\n",
            "Epoch [2/3] Train Acc: 54.17% | Test Acc: 64.46%\n",
            "Epoch [3/3] Train Acc: 55.04% | Test Acc: 73.79%\n",
            "\n",
            "Running: LeakyReLU | xavier | SGD\n",
            "Epoch [1/3] Train Acc: 64.90% | Test Acc: 31.26%\n",
            "Epoch [2/3] Train Acc: 71.66% | Test Acc: 59.50%\n",
            "Epoch [3/3] Train Acc: 75.09% | Test Acc: 32.79%\n",
            "\n",
            "Running: LeakyReLU | xavier | Adam\n",
            "Epoch [1/3] Train Acc: 59.51% | Test Acc: 35.90%\n",
            "Epoch [2/3] Train Acc: 67.58% | Test Acc: 55.88%\n",
            "Epoch [3/3] Train Acc: 71.74% | Test Acc: 54.78%\n",
            "\n",
            "Running: LeakyReLU | xavier | RMSprop\n",
            "Epoch [1/3] Train Acc: 57.26% | Test Acc: 92.37%\n",
            "Epoch [2/3] Train Acc: 63.40% | Test Acc: 16.43%\n",
            "Epoch [3/3] Train Acc: 69.50% | Test Acc: 75.36%\n",
            "\n",
            "Running: LeakyReLU | kaiming | SGD\n",
            "Epoch [1/3] Train Acc: 64.45% | Test Acc: 40.97%\n",
            "Epoch [2/3] Train Acc: 71.76% | Test Acc: 12.51%\n",
            "Epoch [3/3] Train Acc: 74.65% | Test Acc: 29.42%\n",
            "\n",
            "Running: LeakyReLU | kaiming | Adam\n",
            "Epoch [1/3] Train Acc: 61.21% | Test Acc: 42.29%\n",
            "Epoch [2/3] Train Acc: 68.33% | Test Acc: 70.54%\n",
            "Epoch [3/3] Train Acc: 73.89% | Test Acc: 64.42%\n",
            "\n",
            "Running: LeakyReLU | kaiming | RMSprop\n",
            "Epoch [1/3] Train Acc: 58.05% | Test Acc: 81.19%\n",
            "Epoch [2/3] Train Acc: 63.88% | Test Acc: 17.94%\n",
            "Epoch [3/3] Train Acc: 70.47% | Test Acc: 44.17%\n",
            "\n",
            "Running: LeakyReLU | random | SGD\n",
            "Epoch [1/3] Train Acc: 60.91% | Test Acc: 71.25%\n",
            "Epoch [2/3] Train Acc: 67.52% | Test Acc: 58.48%\n",
            "Epoch [3/3] Train Acc: 70.24% | Test Acc: 47.14%\n",
            "\n",
            "Running: LeakyReLU | random | Adam\n",
            "Epoch [1/3] Train Acc: 60.50% | Test Acc: 25.26%\n",
            "Epoch [2/3] Train Acc: 64.75% | Test Acc: 42.03%\n",
            "Epoch [3/3] Train Acc: 70.24% | Test Acc: 53.14%\n",
            "\n",
            "Running: LeakyReLU | random | RMSprop\n",
            "Epoch [1/3] Train Acc: 53.82% | Test Acc: 23.88%\n",
            "Epoch [2/3] Train Acc: 60.60% | Test Acc: 58.10%\n"
          ]
        }
      ],
      "source": [
        "run(\n",
        "    train_loader=cd_train,\n",
        "    test_loader=cd_test,\n",
        "    dataset_name=\"catsdogs\",\n",
        "    num_classes=2,\n",
        "    save_path=\"best_cnn_cats_dogs.pth\",\n",
        "    EPOCHS=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_resnet18(cd_train, cd_test, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65x6OcvIei2l",
        "outputId": "9209062d-1540-4e02-b67a-f0f09d02710f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ResNet-18\n",
            "Epoch 1: Train=95.62% Test=50.42%\n",
            "Epoch 2: Train=96.81% Test=50.31%\n",
            "Epoch 3: Train=96.65% Test=51.65%\n",
            "Epoch 4: Train=97.04% Test=50.17%\n",
            "Epoch 5: Train=97.18% Test=49.94%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}